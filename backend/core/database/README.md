# RedFire ç»Ÿä¸€æ•°æ®åº“ç®¡ç†ç³»ç»Ÿ

## ğŸ¯ æ¦‚è¿°

RedFireç»Ÿä¸€æ•°æ®åº“ç®¡ç†ç³»ç»Ÿä¸ºé‡åŒ–äº¤æ˜“å¹³å°æä¾›å®Œæ•´çš„æ•°æ®åº“è§£å†³æ–¹æ¡ˆï¼Œæ”¯æŒå¤šç§æ•°æ®åº“ç±»å‹ï¼Œå…·å¤‡ä¼ä¸šçº§çš„æ€§èƒ½ã€å¯é æ€§å’Œæ‰©å±•æ€§ã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§

### ğŸ”§ å¤šæ•°æ®åº“æ”¯æŒ
- **MySQL**: ä¸»è¦ä¸šåŠ¡æ•°æ®å­˜å‚¨ï¼Œæ”¯æŒè¯»å†™åˆ†ç¦»
- **Redis**: é«˜æ€§èƒ½ç¼“å­˜å’Œä¼šè¯å­˜å‚¨
- **InfluxDB**: æ—¶åºæ•°æ®å­˜å‚¨ï¼ˆKçº¿ã€Tickæ•°æ®ç­‰ï¼‰
- **MongoDB**: æ—¥å¿—å’Œæ–‡æ¡£å­˜å‚¨
- **PostgreSQL**: å¤‡é€‰å…³ç³»å‹æ•°æ®åº“

### âš¡ æ€§èƒ½ä¼˜åŒ–
- **è¿æ¥æ± ç®¡ç†**: æ™ºèƒ½è¿æ¥æ± é…ç½®å’Œç›‘æ§
- **UTF8MB4å­—ç¬¦é›†**: å®Œæ•´Unicodeæ”¯æŒ
- **è¯»å†™åˆ†ç¦»**: è‡ªåŠ¨è¯»å†™è¯·æ±‚è·¯ç”±å’Œè´Ÿè½½å‡è¡¡
- **ç¼“å­˜ç­–ç•¥**: å¤šçº§ç¼“å­˜å’Œæ™ºèƒ½å¤±æ•ˆæœºåˆ¶
- **æ‰¹é‡æ“ä½œ**: é«˜æ•ˆçš„æ‰¹é‡æ•°æ®å¤„ç†

### ğŸ›¡ï¸ å¯é æ€§ä¿éšœ
- **å¥åº·æ£€æŸ¥**: è‡ªåŠ¨è¿æ¥å¥åº·ç›‘æ§
- **æ•…éšœè½¬ç§»**: è‡ªåŠ¨æ•…éšœæ£€æµ‹å’Œæ¢å¤
- **è¿æ¥é‡è¯•**: æ™ºèƒ½é‡è¯•å’Œç†”æ–­æœºåˆ¶
- **äº‹åŠ¡ç®¡ç†**: å®Œæ•´çš„äº‹åŠ¡æ”¯æŒå’Œå›æ»š

## ğŸ—ï¸ æ¶æ„è®¾è®¡

```
RedFireæ•°æ®åº“æ¶æ„
â”œâ”€â”€ ç»Ÿä¸€æ•°æ®åº“ç®¡ç†å™¨ (UnifiedDatabaseManager)
â”‚   â”œâ”€â”€ MySQLè¿æ¥æ±  (ä¸»ä¸šåŠ¡æ•°æ®)
â”‚   â”œâ”€â”€ Redisè¿æ¥æ±  (ç¼“å­˜)
â”‚   â”œâ”€â”€ InfluxDBå®¢æˆ·ç«¯ (æ—¶åºæ•°æ®)
â”‚   â””â”€â”€ MongoDBå®¢æˆ·ç«¯ (æ—¥å¿—)
â”‚
â”œâ”€â”€ è¯»å†™åˆ†ç¦»ç®¡ç†å™¨ (ReadWriteSplitManager)
â”‚   â”œâ”€â”€ ä¸»èŠ‚ç‚¹ (å†™æ“ä½œ)
â”‚   â”œâ”€â”€ ä»èŠ‚ç‚¹ (è¯»æ“ä½œ)
â”‚   â””â”€â”€ è´Ÿè½½å‡è¡¡å™¨
â”‚
â”œâ”€â”€ ç¼“å­˜ç­–ç•¥ç®¡ç†å™¨ (RedisCacheManager)
â”‚   â”œâ”€â”€ å¤šçº§ç¼“å­˜
â”‚   â”œâ”€â”€ å¤±æ•ˆç­–ç•¥
â”‚   â””â”€â”€ ç¼“å­˜è£…é¥°å™¨
â”‚
â””â”€â”€ ä¸“ç”¨æ•°æ®ç®¡ç†å™¨
    â”œâ”€â”€ äº¤æ˜“æ•°æ®ç®¡ç†å™¨ (TradingDataManager)
    â””â”€â”€ æ—¥å¿—ç®¡ç†å™¨ (LogManager)
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒé…ç½®

å¤åˆ¶å¹¶é…ç½®æ•°æ®åº“ç¯å¢ƒå˜é‡ï¼š

```bash
cp backend/core/database/.env.database .env
```

ç¼–è¾‘ `.env` æ–‡ä»¶ï¼Œé…ç½®æ‚¨çš„æ•°æ®åº“è¿æ¥ä¿¡æ¯ï¼š

```env
# ä¸»æ•°æ®åº“é…ç½® (åŸºäºæ‚¨çš„é…ç½®)
DB_HOST=localhost
DB_PORT=3306
DB_USER=root
DB_PASSWORD=root
DB_NAME=vnpy

# Redisç¼“å­˜é…ç½®
REDIS_HOST=localhost
REDIS_PORT=6379
```

### 2. æ•°æ®åº“åˆå§‹åŒ–

```python
from backend.core.database import initialize_databases

# åˆå§‹åŒ–æ‰€æœ‰æ•°æ®åº“
success = initialize_databases()
if success:
    print("âœ… æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")
else:
    print("âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥")
```

### 3. åŸºæœ¬ä½¿ç”¨

```python
from backend.core.database import (
    get_db_session,
    get_cache_manager,
    get_trading_data_manager
)

# MySQLæ•°æ®åº“æ“ä½œ
with get_db_session() as session:
    result = session.execute("SELECT * FROM users")
    users = result.fetchall()

# Redisç¼“å­˜æ“ä½œ
cache = get_cache_manager()
cache.set("user_data", "user_123", {"name": "å¼ ä¸‰"})
user_data = cache.get("user_data", "user_123")

# æ—¶åºæ•°æ®æ“ä½œ
trading_manager = get_trading_data_manager()
trading_manager.write_kline_data(
    symbol="AAPL",
    timeframe="1m",
    timestamp=datetime.now(),
    open_price=150.00,
    high_price=151.00,
    low_price=149.50,
    close_price=150.75,
    volume=100000
)
```

## ğŸ“š è¯¦ç»†ä½¿ç”¨æŒ‡å—

### MySQLæ•°æ®åº“æ“ä½œ

#### åŸºæœ¬CRUDæ“ä½œ

```python
from backend.core.database import get_db_session
from sqlalchemy import text

# æŸ¥è¯¢æ“ä½œ
with get_db_session() as session:
    # æŸ¥è¯¢ç”¨æˆ·
    result = session.execute(text("SELECT * FROM users WHERE id = :id"), {"id": 1})
    user = result.fetchone()
    
    # ç»Ÿè®¡æŸ¥è¯¢
    result = session.execute(text("SELECT COUNT(*) FROM trading_orders"))
    count = result.scalar()

# æ’å…¥æ“ä½œ
with get_db_session() as session:
    session.execute(text("""
        INSERT INTO users (username, email, password_hash) 
        VALUES (:username, :email, :password)
    """), {
        "username": "newuser",
        "email": "newuser@example.com", 
        "password": "hashed_password"
    })
    # è‡ªåŠ¨æäº¤
```

#### è¯»å†™åˆ†ç¦»

```python
from backend.core.database import get_read_session, get_write_session

# è¯»æ“ä½œ - ä½¿ç”¨ä»åº“
with get_read_session() as session:
    result = session.execute(text("SELECT * FROM users"))
    users = result.fetchall()

# å†™æ“ä½œ - ä½¿ç”¨ä¸»åº“
with get_write_session() as session:
    session.execute(text("UPDATE users SET last_login = NOW() WHERE id = :id"), {"id": 1})
```

#### å¼‚æ­¥æ“ä½œ

```python
from backend.core.database import get_async_db_session
import asyncio

async def async_database_operations():
    async with get_async_db_session() as session:
        result = await session.execute(text("SELECT * FROM users"))
        users = result.fetchall()
        return users

# è¿è¡Œå¼‚æ­¥æ“ä½œ
users = asyncio.run(async_database_operations())
```

### Redisç¼“å­˜æ“ä½œ

#### åŸºæœ¬ç¼“å­˜æ“ä½œ

```python
from backend.core.database import get_cache_manager

# è·å–ç¼“å­˜ç®¡ç†å™¨
cache = get_cache_manager("user_data")  # ä½¿ç”¨é¢„å®šä¹‰é…ç½®

# è®¾ç½®ç¼“å­˜
cache.set("user_profile", "user_123", {
    "name": "å¼ ä¸‰",
    "email": "zhangsan@example.com",
    "preferences": {"theme": "dark"}
}, ttl=3600)  # 1å°æ—¶è¿‡æœŸ

# è·å–ç¼“å­˜
user_profile = cache.get("user_profile", "user_123")

# åˆ é™¤ç¼“å­˜
cache.delete("user_profile", "user_123")

# æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨
exists = cache.exists("user_profile", "user_123")
```

#### ç¼“å­˜è£…é¥°å™¨

```python
from backend.core.database import cache

@cache("api_data", ttl=300)  # 5åˆ†é’Ÿç¼“å­˜
def get_market_data(symbol: str):
    """è·å–å¸‚åœºæ•°æ® - è‡ªåŠ¨ç¼“å­˜ç»“æœ"""
    # æ¨¡æ‹ŸAPIè°ƒç”¨
    return {
        "symbol": symbol,
        "price": 150.25,
        "timestamp": datetime.now().isoformat()
    }

# ç¬¬ä¸€æ¬¡è°ƒç”¨ä¼šæ‰§è¡Œå‡½æ•°å¹¶ç¼“å­˜ç»“æœ
data1 = get_market_data("AAPL")

# ç¬¬äºŒæ¬¡è°ƒç”¨ç›´æ¥ä»ç¼“å­˜è·å–
data2 = get_market_data("AAPL")  # ä»ç¼“å­˜è·å–
```

#### ç¼“å­˜ç»Ÿè®¡å’Œç›‘æ§

```python
# è·å–ç¼“å­˜ç»Ÿè®¡
stats = cache.get_stats()
print(f"å‘½ä¸­ç‡: {stats['hit_rate']}")
print(f"æ€»è¯·æ±‚: {stats['total_requests']}")

# æ¸…ç©ºå‘½åç©ºé—´ç¼“å­˜
cache.clear_namespace("user_profile")
```

### InfluxDBæ—¶åºæ•°æ®æ“ä½œ

#### äº¤æ˜“æ•°æ®å­˜å‚¨

```python
from backend.core.database import get_trading_data_manager
from datetime import datetime

trading_manager = get_trading_data_manager()

# å†™å…¥Kçº¿æ•°æ®
success = trading_manager.write_kline_data(
    symbol="AAPL",
    timeframe="1m",
    timestamp=datetime.now(),
    open_price=150.00,
    high_price=151.00,
    low_price=149.50,
    close_price=150.75,
    volume=100000
)

# å†™å…¥Tickæ•°æ®
success = trading_manager.write_tick_data(
    symbol="AAPL",
    timestamp=datetime.now(),
    last_price=150.75,
    volume=1000,
    bid_price=150.70,
    ask_price=150.80,
    bid_volume=500,
    ask_volume=600
)

# æŸ¥è¯¢å†å²Kçº¿æ•°æ®
kline_data = trading_manager.get_kline_data(
    symbol="AAPL",
    timeframe="1m",
    start_time=datetime.now() - timedelta(hours=1),
    end_time=datetime.now()
)

# è·å–æœ€æ–°ä»·æ ¼
latest_price = trading_manager.get_latest_price("AAPL")
```

#### è‡ªå®šä¹‰æ—¶åºæ•°æ®

```python
from backend.core.database import get_influx_manager, TimeSeriesPoint

influx_manager = get_influx_manager()

# åˆ›å»ºè‡ªå®šä¹‰æ•°æ®ç‚¹
point = TimeSeriesPoint(
    measurement="portfolio_value",
    fields={
        "total_value": 100000.0,
        "cash": 20000.0,
        "positions": 80000.0
    },
    tags={
        "user_id": "user_123",
        "account_type": "live"
    },
    timestamp=datetime.now()
)

# å†™å…¥æ•°æ®ç‚¹
success = influx_manager.write_point(point)
```

### MongoDBæ—¥å¿—æ“ä½œ

#### ç»“æ„åŒ–æ—¥å¿—

```python
from backend.core.database import get_log_manager, LogEntry, LogLevel, LogCategory
import asyncio

async def logging_operations():
    log_manager = get_log_manager()
    
    # åˆ›å»ºæ—¥å¿—æ¡ç›®
    log_entry = LogEntry(
        level=LogLevel.INFO,
        category=LogCategory.TRADING,
        message="ç”¨æˆ·ä¸‹å•æ“ä½œ",
        source="trading_service",
        user_id="user_123",
        data={
            "symbol": "AAPL",
            "quantity": 100,
            "price": 150.00,
            "order_type": "LIMIT"
        },
        tags=["trading", "order", "user_action"]
    )
    
    # å†™å…¥æ—¥å¿—
    log_id = await log_manager.write_log(log_entry)
    print(f"æ—¥å¿—ID: {log_id}")

# è¿è¡Œå¼‚æ­¥æ—¥å¿—æ“ä½œ
asyncio.run(logging_operations())
```

#### å®¡è®¡æ—¥å¿—

```python
async def audit_logging():
    log_manager = get_log_manager()
    
    # å†™å…¥å®¡è®¡æ—¥å¿—
    audit_id = await log_manager.write_audit_log(
        user_id="user_123",
        action="CREATE_ORDER",
        resource="trading_orders",
        details={
            "order_id": "order_456",
            "symbol": "AAPL",
            "side": "BUY",
            "quantity": 100
        },
        ip_address="192.168.1.100",
        user_agent="Mozilla/5.0..."
    )
```

#### æ—¥å¿—æŸ¥è¯¢å’Œåˆ†æ

```python
async def log_analysis():
    log_manager = get_log_manager()
    
    # æŸ¥è¯¢ç‰¹å®šç±»å‹çš„æ—¥å¿—
    logs = await log_manager.query_logs(
        category=LogCategory.TRADING,
        level=LogLevel.ERROR,
        start_time=datetime.now() - timedelta(days=1),
        user_id="user_123",
        limit=100
    )
    
    # è·å–æ—¥å¿—ç»Ÿè®¡
    stats = await log_manager.get_log_statistics(
        start_time=datetime.now() - timedelta(days=7),
        end_time=datetime.now()
    )
    
    print(f"æ€»æ—¥å¿—æ•°: {stats['total']}")
    print(f"é”™è¯¯æ—¥å¿—æ•°: {stats['by_level'].get('ERROR', 0)}")
```

## ğŸ”§ é…ç½®è¯´æ˜

### æ•°æ®åº“è¿æ¥é…ç½®

```env
# MySQLä¸»æ•°æ®åº“
DB_HOST=localhost          # æ•°æ®åº“ä¸»æœº
DB_PORT=3306              # æ•°æ®åº“ç«¯å£
DB_USER=root              # æ•°æ®åº“ç”¨æˆ·å
DB_PASSWORD=root          # æ•°æ®åº“å¯†ç 
DB_NAME=vnpy              # æ•°æ®åº“åç§°

# è¿æ¥æ± ä¼˜åŒ–
DB_POOL_SIZE=15           # è¿æ¥æ± å¤§å°
DB_MAX_OVERFLOW=30        # æœ€å¤§æº¢å‡ºè¿æ¥æ•°
DB_POOL_TIMEOUT=20        # è¿æ¥è¶…æ—¶æ—¶é—´(ç§’)
DB_POOL_RECYCLE=1800      # è¿æ¥å›æ”¶æ—¶é—´(ç§’)
```

### Redisç¼“å­˜é…ç½®

```env
# Redisè¿æ¥
REDIS_HOST=localhost      # Redisä¸»æœº
REDIS_PORT=6379          # Redisç«¯å£
REDIS_DB=0               # Redisæ•°æ®åº“ç¼–å·
REDIS_PASSWORD=          # Rediså¯†ç (å¯é€‰)

# ç¼“å­˜ç­–ç•¥
REDIS_DEFAULT_TTL=3600   # é»˜è®¤è¿‡æœŸæ—¶é—´(ç§’)
REDIS_MAX_CONNECTIONS=20 # æœ€å¤§è¿æ¥æ•°
```

### è¯»å†™åˆ†ç¦»é…ç½®

```env
# ä¸»æ•°æ®åº“(å†™æ“ä½œ)
DB_MASTER_HOST=localhost
DB_MASTER_PORT=3306
DB_MASTER_USER=root
DB_MASTER_PASSWORD=root

# ä»æ•°æ®åº“(è¯»æ“ä½œ) - å¯é€‰
DB_SLAVE_HOST=slave-host
DB_SLAVE_PORT=3306
DB_SLAVE_USER=readonly
DB_SLAVE_PASSWORD=readonly
```

## ğŸ“Š ç›‘æ§å’Œè¯Šæ–­

### æ•°æ®åº“çŠ¶æ€ç›‘æ§

```python
from backend.core.database import get_database_manager, get_database_status

# è·å–æ‰€æœ‰æ•°æ®åº“ç»Ÿè®¡
db_manager = get_database_manager()
stats = db_manager.get_all_stats()

# æµ‹è¯•æ‰€æœ‰æ•°æ®åº“è¿æ¥
health_status = db_manager.test_all_connections()

# è·å–è¯¦ç»†çŠ¶æ€ä¿¡æ¯
status = get_database_status()
print(f"æ•°æ®åº“åˆå§‹åŒ–çŠ¶æ€: {status}")
```

### è¯»å†™åˆ†ç¦»ç›‘æ§

```python
from backend.core.database import get_rw_split_manager

rw_manager = get_rw_split_manager()
rw_stats = rw_manager.get_all_stats()

print(f"è¯»è¯·æ±‚æ•°: {rw_stats['read_queries']}")
print(f"å†™è¯·æ±‚æ•°: {rw_stats['write_queries']}")
print(f"æ•…éšœè½¬ç§»æ¬¡æ•°: {rw_stats['failovers']}")
```

### ç¼“å­˜æ€§èƒ½ç›‘æ§

```python
from backend.core.database import get_cache_manager

cache = get_cache_manager()
cache_stats = cache.get_stats()

print(f"ç¼“å­˜å‘½ä¸­ç‡: {cache_stats['hit_rate']}")
print(f"ç¼“å­˜é”™è¯¯æ•°: {cache_stats['errors']}")
```

## ğŸ› ï¸ æœ€ä½³å®è·µ

### 1. è¿æ¥ç®¡ç†

```python
# âœ… æ¨èï¼šä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨
with get_db_session() as session:
    # æ•°æ®åº“æ“ä½œ
    result = session.execute("SELECT ...")
    # è‡ªåŠ¨æäº¤å’Œå…³é—­è¿æ¥

# âŒ ä¸æ¨èï¼šæ‰‹åŠ¨ç®¡ç†è¿æ¥
session = get_db_session_direct()
try:
    result = session.execute("SELECT ...")
    session.commit()
finally:
    session.close()  # å®¹æ˜“å¿˜è®°
```

### 2. ç¼“å­˜ç­–ç•¥

```python
# âœ… æ¨èï¼šä½¿ç”¨è£…é¥°å™¨ç¼“å­˜
@cache("expensive_operation", ttl=3600)
def expensive_calculation(params):
    # è€—æ—¶è®¡ç®—
    return result

# âœ… æ¨èï¼šåˆç†è®¾ç½®TTL
cache.set("user_session", user_id, session_data, ttl=1800)  # 30åˆ†é’Ÿ
cache.set("market_data", symbol, data, ttl=60)  # 1åˆ†é’Ÿ

# âŒ ä¸æ¨èï¼šæ— é™æœŸç¼“å­˜
cache.set("permanent_data", key, data)  # å¯èƒ½å¯¼è‡´å†…å­˜æ³„æ¼
```

### 3. é”™è¯¯å¤„ç†

```python
# âœ… æ¨èï¼šå®Œæ•´çš„é”™è¯¯å¤„ç†
try:
    with get_write_session() as session:
        session.execute("INSERT INTO ...")
except SQLAlchemyError as e:
    logger.error(f"æ•°æ®åº“æ“ä½œå¤±è´¥: {e}")
    # è®°å½•é”™è¯¯æ—¥å¿—
    await log_manager.write_log(LogEntry(
        level=LogLevel.ERROR,
        category=LogCategory.DATABASE,
        message="æ•°æ®åº“å†™å…¥å¤±è´¥",
        exception=str(e)
    ))
    raise
```

### 4. æ‰¹é‡æ“ä½œ

```python
# âœ… æ¨èï¼šæ‰¹é‡å†™å…¥æ—¶åºæ•°æ®
points = []
for record in large_dataset:
    point = TimeSeriesPoint(...)
    points.append(point)

# æ‰¹é‡å†™å…¥
influx_manager.write_points(points)

# âŒ ä¸æ¨èï¼šé€æ¡å†™å…¥
for record in large_dataset:
    point = TimeSeriesPoint(...)
    influx_manager.write_point(point)  # æ•ˆç‡ä½
```

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **MySQLè¿æ¥å¤±è´¥**
   ```
   é”™è¯¯: Can't connect to MySQL server
   è§£å†³: æ£€æŸ¥DB_HOSTã€DB_PORTã€DB_USERã€DB_PASSWORDé…ç½®
   ```

2. **Redisè¿æ¥è¶…æ—¶**
   ```
   é”™è¯¯: Redis connection timeout
   è§£å†³: æ£€æŸ¥REDIS_HOSTã€REDIS_PORTé…ç½®ï¼Œç¡®è®¤RedisæœåŠ¡è¿è¡Œ
   ```

3. **InfluxDBå†™å…¥å¤±è´¥**
   ```
   é”™è¯¯: InfluxDB write failed
   è§£å†³: æ£€æŸ¥INFLUX_TOKENã€INFLUX_ORGã€INFLUX_BUCKETé…ç½®
   ```

4. **è¿æ¥æ± è€—å°½**
   ```
   é”™è¯¯: QueuePool limit exceeded
   è§£å†³: å¢åŠ DB_POOL_SIZEå’ŒDB_MAX_OVERFLOWå€¼
   ```

### è°ƒè¯•æ¨¡å¼

```python
# å¯ç”¨SQLæ—¥å¿—
import os
os.environ['DB_ECHO'] = 'true'

# å¯ç”¨Redisè°ƒè¯•
os.environ['REDIS_DEBUG'] = 'true'

# æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯
import logging
logging.basicConfig(level=logging.DEBUG)
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. è¿æ¥æ± è°ƒä¼˜

```env
# é«˜å¹¶å‘ç¯å¢ƒ
DB_POOL_SIZE=25
DB_MAX_OVERFLOW=50
DB_POOL_TIMEOUT=10

# ä½å»¶è¿Ÿç¯å¢ƒ
DB_POOL_RECYCLE=900  # 15åˆ†é’Ÿå›æ”¶
DB_POOL_TIMEOUT=5    # å¿«é€Ÿå¤±è´¥
```

### 2. ç¼“å­˜ä¼˜åŒ–

```python
# åˆ†å±‚ç¼“å­˜ç­–ç•¥
@cache("hot_data", ttl=60)      # çƒ­æ•°æ®1åˆ†é’Ÿ
@cache("warm_data", ttl=600)    # æ¸©æ•°æ®10åˆ†é’Ÿ
@cache("cold_data", ttl=3600)   # å†·æ•°æ®1å°æ—¶
```

### 3. è¯»å†™åˆ†ç¦»ä¼˜åŒ–

```python
# è¯»å¯†é›†å‹åº”ç”¨
# é…ç½®å¤šä¸ªä»èŠ‚ç‚¹
DB_SLAVE_HOST_1=slave1
DB_SLAVE_HOST_2=slave2
DB_SLAVE_HOST_3=slave3
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤Issueå’ŒPull Requestæ¥æ”¹è¿›RedFireæ•°æ®åº“ç®¡ç†ç³»ç»Ÿã€‚

### å¼€å‘ç¯å¢ƒè®¾ç½®

```bash
# 1. å…‹éš†é¡¹ç›®
git clone <repository>

# 2. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 3. é…ç½®æ•°æ®åº“
cp backend/core/database/.env.database .env

# 4. è¿è¡Œæµ‹è¯•
python -m pytest backend/core/database/tests/

# 5. è¿è¡Œç¤ºä¾‹
python backend/core/database/usage_examples.py
```

## ğŸ“„ è®¸å¯è¯

MIT License - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

---

**RedFireæ•°æ®åº“ç®¡ç†ç³»ç»Ÿ** - ä¸ºé‡åŒ–äº¤æ˜“å¹³å°æä¾›ä¼ä¸šçº§æ•°æ®åº“è§£å†³æ–¹æ¡ˆ ğŸš€
