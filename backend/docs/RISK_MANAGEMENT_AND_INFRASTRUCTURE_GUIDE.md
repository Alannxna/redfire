# é£é™©ç®¡ç†å’ŒåŸºç¡€è®¾æ–½å®Œå–„æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»RedFireäº¤æ˜“ç³»ç»Ÿä¸­å®Œå–„çš„é£é™©ç®¡ç†æ¨¡å—å’ŒåŸºç¡€è®¾æ–½ç»„ä»¶ï¼ŒåŒ…æ‹¬VaRè®¡ç®—ã€å‹åŠ›æµ‹è¯•ã€å®æ—¶ç›‘æ§ã€å¤šçº§ç¼“å­˜ç³»ç»Ÿå’ŒKafkaæ¶ˆæ¯é˜Ÿåˆ—ã€‚

## ğŸ”¥ é£é™©ç®¡ç†æ¨¡å—

### 1. VaRè®¡ç®—å¼•æ“

æ”¯æŒä¸‰ç§VaRè®¡ç®—æ–¹æ³•ï¼š

#### 1.1 å†å²æ¨¡æ‹ŸVaR
```python
from src.domain.trading.services.enhanced_risk_service import EnhancedRiskService

risk_service = EnhancedRiskService()

# è®¡ç®—å†å²æ¨¡æ‹ŸVaR
var_result = await risk_service.calculate_historical_var(
    positions=positions,
    confidence_level=0.95,
    time_horizon=1,
    lookback_days=252
)

print(f"VaR(95%): {var_result.var_value}")
print(f"æœŸæœ›æŸå¤±: {var_result.expected_shortfall}")
```

#### 1.2 å‚æ•°VaR
```python
# è®¡ç®—å‚æ•°VaRï¼ˆå‡è®¾æ­£æ€åˆ†å¸ƒï¼‰
var_result = await risk_service.calculate_parametric_var(
    positions=positions,
    confidence_level=0.95,
    time_horizon=1
)
```

#### 1.3 è’™ç‰¹å¡æ´›VaR
```python
# è®¡ç®—è’™ç‰¹å¡æ´›VaR
var_result = await risk_service.calculate_monte_carlo_var(
    positions=positions,
    confidence_level=0.95,
    time_horizon=1,
    simulations=10000
)
```

### 2. å‹åŠ›æµ‹è¯•ç³»ç»Ÿ

#### 2.1 åˆ›å»ºå‹åŠ›æµ‹è¯•æƒ…æ™¯
```python
from src.domain.trading.services.enhanced_risk_service import StressTestScenario

# åˆ›å»ºå¸‚åœºæš´è·Œæƒ…æ™¯
crash_scenario = StressTestScenario(
    scenario_id="MARKET_CRASH_2024",
    name="2024å¹´å¸‚åœºæš´è·Œ",
    description="è‚¡ç¥¨å¸‚åœºä¸‹è·Œ25%çš„æç«¯æƒ…æ™¯",
    market_shocks={
        "AAPL": Decimal("-0.25"),
        "MSFT": Decimal("-0.20"),
        "GOOGL": Decimal("-0.30")
    }
)

await risk_service.add_stress_scenario(crash_scenario)
```

#### 2.2 è¿è¡Œå‹åŠ›æµ‹è¯•
```python
# è¿è¡Œå‹åŠ›æµ‹è¯•
stress_result = await risk_service.run_stress_test(
    scenario_id="MARKET_CRASH_2024",
    positions=positions,
    market_data=current_market_data
)

print(f"å‹åŠ›æµ‹è¯•ç›ˆäº: {stress_result.portfolio_pnl}")
print(f"æœ€å¤§å•å“ç§æŸå¤±: {min(stress_result.position_impacts.values())}")
```

#### 2.3 å†å²æƒ…æ™¯å›æµ‹
```python
from datetime import datetime, timedelta

# åˆ›å»ºå†å²æƒ…æ™¯
start_date = datetime(2020, 3, 1)  # 2020å¹´3æœˆç–«æƒ…æš´è·Œ
end_date = datetime(2020, 4, 1)

historical_scenario = await risk_service.create_historical_scenario(
    scenario_id="COVID_CRASH_2020",
    name="æ–°å† ç–«æƒ…æš´è·Œ",
    description="2020å¹´3æœˆç–«æƒ…å¼•å‘çš„å¸‚åœºæš´è·Œ",
    start_date=start_date,
    end_date=end_date
)

# è¿è¡Œå†å²å›æµ‹
backtest_result = await risk_service.run_historical_backtest(
    scenario_id="COVID_CRASH_2020",
    positions=positions,
    initial_portfolio_value=Decimal("1000000")
)

print(f"å›æµ‹æ€»ç›ˆäº: {backtest_result.total_pnl}")
print(f"æœ€å¤§å›æ’¤: {backtest_result.max_drawdown}")
print(f"å¤æ™®æ¯”ç‡: {backtest_result.sharpe_ratio}")
```

### 3. å®æ—¶é£é™©ç›‘æ§

#### 3.1 æ·»åŠ ç›‘æ§è§„åˆ™
```python
from src.domain.trading.services.enhanced_risk_service import MonitoringRule, MonitoringFrequency
from src.domain.trading.services.advanced_risk_service import RiskLevel

# åˆ›å»ºè‡ªå®šä¹‰ç›‘æ§è§„åˆ™
custom_rule = MonitoringRule(
    rule_id="CUSTOM_VAR_LIMIT",
    name="è‡ªå®šä¹‰VaRé™é¢",
    description="VaRä¸å¾—è¶…è¿‡æ€»èµ„äº§çš„3%",
    metric_name="var_95_ratio",
    threshold=Decimal("0.03"),
    comparison=">",
    severity=RiskLevel.CRITICAL,
    frequency=MonitoringFrequency.REAL_TIME
)

await risk_service.add_monitoring_rule(custom_rule)
```

#### 3.2 è¿è¡Œç»¼åˆç›‘æ§
```python
# è¿è¡Œå®æ—¶é£é™©ç›‘æ§
alerts = await risk_service.run_comprehensive_monitoring(
    positions=positions,
    accounts=accounts,
    market_data=market_data
)

for alert in alerts:
    print(f"é£é™©å‘Šè­¦: {alert.message}")
    print(f"ä¸¥é‡ç¨‹åº¦: {alert.severity.value}")
    print(f"è¯¦ç»†ä¿¡æ¯: {alert.details}")
```

#### 3.3 è·å–é£é™©æŒ‡æ ‡
```python
# è®¡ç®—ç»¼åˆé£é™©æŒ‡æ ‡
risk_metrics = await risk_service.calculate_comprehensive_risk_metrics(
    positions=positions,
    accounts=accounts,
    market_data=market_data
)

print(f"VaR(95%): {risk_metrics.var_95}")
print(f"VaR(99%): {risk_metrics.var_99}")
print(f"æœ€å¤§å›æ’¤: {risk_metrics.max_drawdown}")
print(f"æŠ•èµ„ç»„åˆBeta: {risk_metrics.beta}")
print(f"é›†ä¸­åº¦é£é™©: {risk_metrics.concentration_risk}")
print(f"æµåŠ¨æ€§é£é™©: {risk_metrics.liquidity_risk}")
```

### 4. è‡ªåŠ¨é£é™©æ§åˆ¶

#### 4.1 è®¢å•é¢„æ£€æŸ¥
```python
from src.domain.trading.entities.order_entity import Order

# æ–°è®¢å•é£é™©æ£€æŸ¥
new_order = Order(
    symbol="AAPL",
    direction=Direction.LONG,
    volume=Decimal("1000"),
    price=Decimal("150.00")
)

allow_order, control_actions = await risk_service.auto_risk_control(
    order=new_order,
    positions=positions,
    accounts=accounts,
    market_data=market_data
)

if not allow_order:
    print("è®¢å•è¢«é£é™©æ§åˆ¶ç³»ç»Ÿæ‹’ç»:")
    for action in control_actions:
        print(f"- {action}")
else:
    print("è®¢å•é€šè¿‡é£é™©æ£€æŸ¥ï¼Œå¯ä»¥æ‰§è¡Œ")
```

## ğŸ—ï¸ åŸºç¡€è®¾æ–½æ¨¡å—

### 1. å¤šçº§ç¼“å­˜ç³»ç»Ÿ

#### 1.1 åŸºæœ¬ä½¿ç”¨
```python
from src.infrastructure.cache.multi_level_cache import get_cache

# è·å–å…¨å±€ç¼“å­˜å®ä¾‹
cache = await get_cache()

# è®¾ç½®ç¼“å­˜
await cache.set("user:123", {"name": "å¼ ä¸‰", "balance": 100000})

# è·å–ç¼“å­˜
user_data = await cache.get("user:123")
print(user_data)  # {'name': 'å¼ ä¸‰', 'balance': 100000}

# åˆ é™¤ç¼“å­˜
await cache.delete("user:123")
```

#### 1.2 é…ç½®ç¼“å­˜å±‚çº§
```python
from src.infrastructure.cache.multi_level_cache import MultiLevelCache, CacheLevel

# è‡ªå®šä¹‰ç¼“å­˜é…ç½®
l1_config = {
    "max_size": 1000,
    "max_memory": 100 * 1024 * 1024,  # 100MB
    "eviction_policy": "LRU"
}

l2_config = {
    "redis_url": "redis://localhost:6379",
    "db": 1,
    "key_prefix": "trading:",
    "default_ttl": 3600
}

l3_config = {
    "cache_dir": "/var/cache/redfire",
    "max_files": 10000,
    "default_ttl": 86400
}

cache = MultiLevelCache(
    l1_config=l1_config,
    l2_config=l2_config,
    l3_config=l3_config
)

await cache.initialize()
```

#### 1.3 ç¼“å­˜è£…é¥°å™¨
```python
from src.infrastructure.cache.multi_level_cache import cache_decorator

@cache_decorator(ttl=3600)
async def get_market_data(symbol: str) -> dict:
    # æ¨¡æ‹Ÿä»å¤–éƒ¨APIè·å–å¸‚åœºæ•°æ®
    return {
        "symbol": symbol,
        "price": 150.00,
        "timestamp": datetime.now().isoformat()
    }

# ç¬¬ä¸€æ¬¡è°ƒç”¨ä¼šä»APIè·å–æ•°æ®å¹¶ç¼“å­˜
data1 = await get_market_data("AAPL")

# ç¬¬äºŒæ¬¡è°ƒç”¨ç›´æ¥ä»ç¼“å­˜è¿”å›
data2 = await get_market_data("AAPL")  # ä»ç¼“å­˜è·å–
```

#### 1.4 ç¼“å­˜é¢„çƒ­
```python
# å®šä¹‰æ•°æ®åŠ è½½å™¨
async def load_user_data(user_id: str) -> dict:
    # ä»æ•°æ®åº“åŠ è½½ç”¨æˆ·æ•°æ®
    return {"user_id": user_id, "name": f"User_{user_id}"}

# é¢„çƒ­ç¼“å­˜
user_ids = ["1001", "1002", "1003", "1004", "1005"]
await cache.warmup(user_ids, load_user_data)
```

#### 1.5 è·å–ç¼“å­˜ç»Ÿè®¡
```python
# è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
stats = await cache.get_stats()

print(f"æ€»å‘½ä¸­ç‡: {stats['total_stats']['hit_rate']:.2%}")
print(f"L1ç¼“å­˜å‘½ä¸­ç‡: {stats['l1_stats']['hit_rate']:.2%}")
print(f"L2ç¼“å­˜å‘½ä¸­ç‡: {stats['l2_stats']['hit_rate']:.2%}")
print(f"L3ç¼“å­˜å‘½ä¸­ç‡: {stats['l3_stats']['hit_rate']:.2%}")
```

### 2. Kafkaæ¶ˆæ¯é˜Ÿåˆ—ç³»ç»Ÿ

#### 2.1 åŸºæœ¬æ¶ˆæ¯å‘é€
```python
from src.infrastructure.messaging.kafka_service import get_message_service, Message, MessageType

# è·å–æ¶ˆæ¯æœåŠ¡
message_service = await get_message_service()

# åˆ›å»ºæ¶ˆæ¯
trade_message = Message(
    key="TRADE_001",
    value={
        "order_id": "ORDER_123",
        "symbol": "AAPL",
        "quantity": 100,
        "price": 150.00,
        "timestamp": datetime.now().isoformat()
    },
    headers={"source": "trading_engine"},
    message_type=MessageType.TRADE_ORDER
)

# å‘é€æ¶ˆæ¯
success = await message_service.send_message("trade_orders", trade_message)
if success:
    print("äº¤æ˜“è®¢å•æ¶ˆæ¯å‘é€æˆåŠŸ")
```

#### 2.2 æ‰¹é‡å‘é€æ¶ˆæ¯
```python
# æ‰¹é‡å‘é€å¸‚åœºæ•°æ®
market_messages = []
for symbol in ["AAPL", "MSFT", "GOOGL"]:
    message = {
        "key": symbol,
        "value": {
            "symbol": symbol,
            "price": 150.00,
            "volume": 1000,
            "timestamp": datetime.now().isoformat()
        }
    }
    market_messages.append(message)

success_count, failed_count = await message_service.send_batch(
    "market_data", 
    market_messages
)

print(f"æ‰¹é‡å‘é€: æˆåŠŸ {success_count}, å¤±è´¥ {failed_count}")
```

#### 2.3 æ¶ˆæ¯æ¶ˆè´¹
```python
from src.infrastructure.messaging.kafka_service import message_handler

@message_handler("trade_orders", "risk_monitor_group")
async def handle_trade_order(message: Message):
    """å¤„ç†äº¤æ˜“è®¢å•æ¶ˆæ¯"""
    order_data = message.value
    print(f"æ”¶åˆ°äº¤æ˜“è®¢å•: {order_data['order_id']}")
    
    # æ‰§è¡Œé£é™©æ£€æŸ¥
    if order_data['quantity'] > 1000:
        print("å¤§é¢è®¢å•ï¼Œéœ€è¦é¢å¤–å®¡æ‰¹")
    
    # æ›´æ–°è®¢å•çŠ¶æ€
    print(f"è®¢å• {order_data['order_id']} å¤„ç†å®Œæˆ")

@message_handler("risk_alerts", "alert_processor_group")
async def handle_risk_alert(message: Message):
    """å¤„ç†é£é™©å‘Šè­¦æ¶ˆæ¯"""
    alert_data = message.value
    print(f"æ”¶åˆ°é£é™©å‘Šè­¦: {alert_data['severity']} - {alert_data['message']}")
    
    # æ ¹æ®ä¸¥é‡ç¨‹åº¦å¤„ç†
    if alert_data['severity'] == 'CRITICAL':
        print("å‘é€ç´§æ€¥é€šçŸ¥ç»™é£é™©ç®¡ç†å‘˜")
    
    # è®°å½•å‘Šè­¦æ—¥å¿—
    print(f"å‘Šè­¦å·²è®°å½•: {alert_data['alert_id']}")
```

#### 2.4 åˆ›å»ºä¸»é¢˜
```python
from src.infrastructure.messaging.kafka_service import TopicConfig, CompressionType

# åˆ›å»ºè‡ªå®šä¹‰ä¸»é¢˜
custom_topic = TopicConfig(
    name="portfolio_updates",
    num_partitions=6,
    replication_factor=1,
    retention_ms=604800000,  # 7å¤©
    compression_type=CompressionType.LZ4
)

success = await message_service.topic_manager.create_topic(custom_topic)
if success:
    print("è‡ªå®šä¹‰ä¸»é¢˜åˆ›å»ºæˆåŠŸ")
```

#### 2.5 è·å–æ¶ˆæ¯ç»Ÿè®¡
```python
# è·å–æ¶ˆæ¯æœåŠ¡ç»Ÿè®¡
stats = await message_service.get_stats()

print(f"æœåŠ¡è¿è¡ŒçŠ¶æ€: {stats['is_running']}")
print(f"ç”Ÿäº§è€…å‘é€æ¶ˆæ¯æ•°: {stats['producer_stats']['messages_sent']}")
print(f"å¯ç”¨ä¸»é¢˜: {stats['topics']}")

# æ¶ˆè´¹è€…ç»Ÿè®¡
for group_id, consumer_stats in stats['consumer_stats'].items():
    print(f"æ¶ˆè´¹è€…ç»„ {group_id}: æ¶ˆè´¹ {consumer_stats['messages_consumed']} æ¡æ¶ˆæ¯")
```

## ğŸ”§ é›†æˆç¤ºä¾‹

### 1. å®Œæ•´çš„é£é™©ç›‘æ§å·¥ä½œæµ
```python
async def risk_monitoring_workflow():
    """å®Œæ•´çš„é£é™©ç›‘æ§å·¥ä½œæµ"""
    
    # 1. åˆå§‹åŒ–æœåŠ¡
    risk_service = EnhancedRiskService()
    cache = await get_cache()
    message_service = await get_message_service()
    
    # 2. è·å–å½“å‰æŒä»“å’Œå¸‚åœºæ•°æ®
    positions = await get_current_positions()
    accounts = await get_current_accounts()
    market_data = await get_market_data()
    
    # 3. è®¡ç®—é£é™©æŒ‡æ ‡
    risk_metrics = await risk_service.calculate_comprehensive_risk_metrics(
        positions, accounts, market_data
    )
    
    # 4. ç¼“å­˜é£é™©æŒ‡æ ‡
    await cache.set(
        "latest_risk_metrics", 
        risk_metrics.to_dict(), 
        ttl=300  # 5åˆ†é’Ÿç¼“å­˜
    )
    
    # 5. è¿è¡Œç›‘æ§æ£€æŸ¥
    alerts = await risk_service.run_comprehensive_monitoring(
        positions, accounts, market_data
    )
    
    # 6. å‘é€é£é™©å‘Šè­¦
    for alert in alerts:
        alert_message = Message(
            key=alert.alert_id,
            value=alert.to_dict(),
            message_type=MessageType.RISK_ALERT
        )
        
        await message_service.send_message("risk_alerts", alert_message)
    
    # 7. è¿è¡Œå‹åŠ›æµ‹è¯•ï¼ˆå®šæœŸï¼‰
    if should_run_stress_test():
        for scenario_id in ["MARKET_CRASH", "RATE_RISE", "EM_CRISIS"]:
            stress_result = await risk_service.run_stress_test(
                scenario_id, positions, market_data
            )
            
            # å‘é€å‹åŠ›æµ‹è¯•ç»“æœ
            stress_message = Message(
                key=f"stress_test_{scenario_id}",
                value=stress_result.to_dict(),
                message_type=MessageType.SYSTEM_EVENT
            )
            
            await message_service.send_message("system_events", stress_message)
    
    print(f"é£é™©ç›‘æ§å®Œæˆ: {len(alerts)} ä¸ªå‘Šè­¦, é£é™©æŒ‡æ ‡å·²æ›´æ–°")
```

### 2. äº¤æ˜“è®¢å•é£é™©æ£€æŸ¥
```python
async def process_trading_order(order_data: dict):
    """å¤„ç†äº¤æ˜“è®¢å•çš„é£é™©æ£€æŸ¥"""
    
    # 1. ä»ç¼“å­˜è·å–å½“å‰é£é™©çŠ¶æ€
    cache = await get_cache()
    current_risk = await cache.get("latest_risk_metrics")
    
    if current_risk and current_risk["var_95_ratio"] > 0.05:
        print("å½“å‰VaRè¶…é™ï¼Œæš‚åœæ–°è®¢å•")
        return False
    
    # 2. åˆ›å»ºè®¢å•å¯¹è±¡
    order = Order(**order_data)
    
    # 3. è·å–å½“å‰çŠ¶æ€
    positions = await get_current_positions()
    accounts = await get_current_accounts()
    market_data = await get_market_data()
    
    # 4. é£é™©æ§åˆ¶æ£€æŸ¥
    risk_service = EnhancedRiskService()
    allow_order, control_actions = await risk_service.auto_risk_control(
        order, positions, accounts, market_data
    )
    
    # 5. å‘é€å†³ç­–æ¶ˆæ¯
    message_service = await get_message_service()
    decision_message = Message(
        key=order.order_id,
        value={
            "order_id": order.order_id,
            "allow_order": allow_order,
            "control_actions": control_actions,
            "timestamp": datetime.now().isoformat()
        },
        message_type=MessageType.SYSTEM_EVENT
    )
    
    await message_service.send_message("order_decisions", decision_message)
    
    return allow_order
```

### 3. ç¼“å­˜ä¼˜åŒ–çš„æ•°æ®è®¿é—®
```python
from src.infrastructure.cache.multi_level_cache import cache_decorator

@cache_decorator(ttl=1800)  # 30åˆ†é’Ÿç¼“å­˜
async def get_portfolio_analytics(user_id: str) -> dict:
    """è·å–æŠ•èµ„ç»„åˆåˆ†ææ•°æ®"""
    
    # ä»æ•°æ®åº“è·å–æŒä»“
    positions = await db.get_user_positions(user_id)
    
    # è®¡ç®—åˆ†ææŒ‡æ ‡
    risk_service = EnhancedRiskService()
    
    # VaRè®¡ç®—
    var_result = await risk_service.calculate_historical_var(positions)
    
    # ç»„åˆç»Ÿè®¡
    total_value = sum(pos.market_value for pos in positions)
    largest_position = max(positions, key=lambda p: p.market_value)
    
    return {
        "user_id": user_id,
        "total_value": float(total_value),
        "var_95": float(var_result.var_value),
        "largest_position": {
            "symbol": largest_position.symbol,
            "value": float(largest_position.market_value),
            "ratio": float(largest_position.market_value / total_value)
        },
        "calculated_at": datetime.now().isoformat()
    }

# ä½¿ç”¨ç¼“å­˜çš„åˆ†ææ•°æ®
user_analytics = await get_portfolio_analytics("user_123")
print(f"ç”¨æˆ·æŠ•èµ„ç»„åˆä»·å€¼: {user_analytics['total_value']}")
```

## ğŸ“Š ç›‘æ§å’Œè¯Šæ–­

### 1. ç³»ç»Ÿå¥åº·æ£€æŸ¥
```python
async def system_health_check():
    """ç³»ç»Ÿå¥åº·æ£€æŸ¥"""
    
    health_status = {
        "timestamp": datetime.now().isoformat(),
        "services": {}
    }
    
    # æ£€æŸ¥ç¼“å­˜ç³»ç»Ÿ
    try:
        cache = await get_cache()
        cache_stats = await cache.get_stats()
        health_status["services"]["cache"] = {
            "status": "healthy",
            "hit_rate": cache_stats["total_stats"]["hit_rate"],
            "enabled_levels": cache_stats["enabled_levels"]
        }
    except Exception as e:
        health_status["services"]["cache"] = {
            "status": "unhealthy",
            "error": str(e)
        }
    
    # æ£€æŸ¥æ¶ˆæ¯é˜Ÿåˆ—
    try:
        message_service = await get_message_service()
        msg_stats = await message_service.get_stats()
        health_status["services"]["messaging"] = {
            "status": "healthy",
            "is_running": msg_stats["is_running"],
            "topics": len(msg_stats["topics"])
        }
    except Exception as e:
        health_status["services"]["messaging"] = {
            "status": "unhealthy",
            "error": str(e)
        }
    
    # æ£€æŸ¥é£é™©ç®¡ç†
    try:
        risk_service = EnhancedRiskService()
        risk_summary = await risk_service.get_enhanced_risk_summary()
        health_status["services"]["risk_management"] = {
            "status": "healthy",
            "monitoring_enabled": risk_summary["monitoring_enabled"],
            "active_rules": risk_summary["active_monitoring_rules"]
        }
    except Exception as e:
        health_status["services"]["risk_management"] = {
            "status": "unhealthy",
            "error": str(e)
        }
    
    return health_status
```

### 2. æ€§èƒ½æŒ‡æ ‡ç›‘æ§
```python
async def collect_performance_metrics():
    """æ”¶é›†æ€§èƒ½æŒ‡æ ‡"""
    
    metrics = {
        "timestamp": datetime.now().isoformat(),
        "cache_metrics": {},
        "messaging_metrics": {},
        "risk_metrics": {}
    }
    
    # ç¼“å­˜æŒ‡æ ‡
    cache = await get_cache()
    cache_stats = await cache.get_stats()
    
    metrics["cache_metrics"] = {
        "l1_hit_rate": cache_stats["l1_stats"]["hit_rate"],
        "l2_hit_rate": cache_stats["l2_stats"]["hit_rate"],
        "l3_hit_rate": cache_stats["l3_stats"]["hit_rate"],
        "total_hit_rate": cache_stats["total_stats"]["hit_rate"],
        "l1_size_mb": cache_stats["l1_stats"]["size"] / (1024 * 1024),
        "l3_size_mb": cache_stats["l3_stats"]["size"] / (1024 * 1024)
    }
    
    # æ¶ˆæ¯é˜Ÿåˆ—æŒ‡æ ‡
    message_service = await get_message_service()
    msg_stats = await message_service.get_stats()
    
    metrics["messaging_metrics"] = {
        "messages_sent": msg_stats["producer_stats"]["messages_sent"],
        "messages_failed": msg_stats["producer_stats"]["messages_failed"],
        "bytes_sent_mb": msg_stats["producer_stats"]["bytes_sent"] / (1024 * 1024),
        "active_topics": len(msg_stats["topics"])
    }
    
    # é£é™©ç®¡ç†æŒ‡æ ‡
    risk_service = EnhancedRiskService()
    risk_summary = await risk_service.get_enhanced_risk_summary()
    
    if risk_summary.get("latest_risk_metrics"):
        latest_metrics = risk_summary["latest_risk_metrics"]
        metrics["risk_metrics"] = {
            "var_95": latest_metrics["var_95"],
            "max_drawdown": latest_metrics["max_drawdown"],
            "concentration_risk": latest_metrics["concentration_risk"],
            "liquidity_risk": latest_metrics["liquidity_risk"]
        }
    
    return metrics
```

## ğŸš€ éƒ¨ç½²å’Œé…ç½®

### 1. ç¯å¢ƒé…ç½®
```bash
# Redisé…ç½®
REDIS_URL=redis://localhost:6379
REDIS_DB=0
REDIS_KEY_PREFIX=redfire:

# Kafkaé…ç½®
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_CLIENT_ID_PREFIX=redfire
KAFKA_COMPRESSION_TYPE=gzip

# ç¼“å­˜é…ç½®
CACHE_L1_MAX_SIZE=1000
CACHE_L1_MAX_MEMORY_MB=100
CACHE_L2_TTL_SECONDS=3600
CACHE_L3_DIR=/var/cache/redfire
CACHE_L3_MAX_FILES=10000

# é£é™©ç®¡ç†é…ç½®
RISK_VAR_CONFIDENCE_LEVEL=0.95
RISK_MAX_VAR_RATIO=0.05
RISK_MAX_POSITION_RATIO=0.20
RISK_MONITORING_FREQUENCY=60
```

### 2. æœåŠ¡å¯åŠ¨è„šæœ¬
```python
async def start_risk_infrastructure():
    """å¯åŠ¨é£é™©ç®¡ç†å’ŒåŸºç¡€è®¾æ–½æœåŠ¡"""
    
    print("å¯åŠ¨RedFireé£é™©ç®¡ç†å’ŒåŸºç¡€è®¾æ–½æœåŠ¡...")
    
    # 1. åˆå§‹åŒ–ç¼“å­˜ç³»ç»Ÿ
    print("åˆå§‹åŒ–å¤šçº§ç¼“å­˜ç³»ç»Ÿ...")
    cache = await get_cache()
    print("âœ“ ç¼“å­˜ç³»ç»Ÿå¯åŠ¨æˆåŠŸ")
    
    # 2. å¯åŠ¨æ¶ˆæ¯é˜Ÿåˆ—
    print("å¯åŠ¨Kafkaæ¶ˆæ¯é˜Ÿåˆ—...")
    message_service = await get_message_service()
    print("âœ“ æ¶ˆæ¯é˜Ÿåˆ—å¯åŠ¨æˆåŠŸ")
    
    # 3. åˆå§‹åŒ–é£é™©ç®¡ç†
    print("åˆå§‹åŒ–é£é™©ç®¡ç†æœåŠ¡...")
    risk_service = EnhancedRiskService()
    await risk_service.create_default_scenarios()
    print("âœ“ é£é™©ç®¡ç†æœåŠ¡å¯åŠ¨æˆåŠŸ")
    
    # 4. è¿è¡Œå¥åº·æ£€æŸ¥
    print("è¿è¡Œç³»ç»Ÿå¥åº·æ£€æŸ¥...")
    health = await system_health_check()
    
    unhealthy_services = [
        name for name, status in health["services"].items() 
        if status["status"] == "unhealthy"
    ]
    
    if unhealthy_services:
        print(f"âš  è­¦å‘Š: ä»¥ä¸‹æœåŠ¡çŠ¶æ€å¼‚å¸¸: {unhealthy_services}")
    else:
        print("âœ“ æ‰€æœ‰æœåŠ¡å¥åº·æ£€æŸ¥é€šè¿‡")
    
    print("RedFireé£é™©ç®¡ç†å’ŒåŸºç¡€è®¾æ–½æœåŠ¡å¯åŠ¨å®Œæˆ!")
    return {
        "cache": cache,
        "messaging": message_service,
        "risk_management": risk_service
    }

# å¯åŠ¨æœåŠ¡
if __name__ == "__main__":
    import asyncio
    services = asyncio.run(start_risk_infrastructure())
```

## ğŸ“ æ€»ç»“

æœ¬æŒ‡å—å±•ç¤ºäº†RedFireäº¤æ˜“ç³»ç»Ÿä¸­å®Œå–„çš„é£é™©ç®¡ç†å’ŒåŸºç¡€è®¾æ–½æ¨¡å—ï¼š

### é£é™©ç®¡ç†ç‰¹æ€§
- âœ… **ä¸‰ç§VaRè®¡ç®—æ–¹æ³•**: å†å²æ¨¡æ‹Ÿã€å‚æ•°ã€è’™ç‰¹å¡æ´›
- âœ… **å‹åŠ›æµ‹è¯•ç³»ç»Ÿ**: å¸‚åœºæƒ…æ™¯åˆ†æå’Œå†å²å›æµ‹
- âœ… **å®æ—¶ç›‘æ§**: è‡ªå®šä¹‰è§„åˆ™å’Œå…¨é¢é£é™©æŒ‡æ ‡
- âœ… **è‡ªåŠ¨æ§åˆ¶**: è®¢å•é¢„æ£€æŸ¥å’Œé£é™©é™é¢æ§åˆ¶

### åŸºç¡€è®¾æ–½ç‰¹æ€§
- âœ… **å¤šçº§ç¼“å­˜**: L1å†…å­˜ã€L2 Redisã€L3æŒä¹…åŒ–
- âœ… **æ¶ˆæ¯é˜Ÿåˆ—**: Kafkaç”Ÿäº§è€…/æ¶ˆè´¹è€…å’Œä¸»é¢˜ç®¡ç†
- âœ… **é«˜æ€§èƒ½**: å¼‚æ­¥å¤„ç†å’Œå¹¶å‘ä¼˜åŒ–
- âœ… **å¯æ‰©å±•**: æ¨¡å—åŒ–è®¾è®¡å’Œé…ç½®åŒ–ç®¡ç†

### ç”Ÿäº§å°±ç»ª
- âœ… **é”™è¯¯å¤„ç†**: å®Œæ•´çš„å¼‚å¸¸å¤„ç†å’Œé™çº§ç­–ç•¥
- âœ… **ç›‘æ§å‘Šè­¦**: å¥åº·æ£€æŸ¥å’Œæ€§èƒ½æŒ‡æ ‡
- âœ… **æµ‹è¯•è¦†ç›–**: å®Œæ•´çš„å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•
- âœ… **æ–‡æ¡£å®Œæ•´**: è¯¦ç»†çš„ä½¿ç”¨æŒ‡å—å’Œç¤ºä¾‹ä»£ç 

è¿™å¥—å®Œæ•´çš„é£é™©ç®¡ç†å’ŒåŸºç¡€è®¾æ–½ç³»ç»Ÿä¸ºRedFireäº¤æ˜“å¹³å°æä¾›äº†ä¼ä¸šçº§çš„å¯é æ€§ã€æ€§èƒ½å’Œå®‰å…¨æ€§ä¿éšœã€‚
