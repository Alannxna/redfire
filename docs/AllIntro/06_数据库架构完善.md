# ðŸ“‹ TODO-06: æ•°æ®åº“æž¶æž„å®Œå–„

## ðŸŽ¯ ä»»åŠ¡æ¦‚è¿°

**ä»»åŠ¡ID**: db_06  
**ä¼˜å…ˆçº§**: é«˜  
**å®žé™…å·¥æœŸ**: 1å¤©  
**è´Ÿè´£æ¨¡å—**: æ•°æ®åº“æž¶æž„ä¼˜åŒ–

### é—®é¢˜æè¿°
å½“å‰RedFireåŽç«¯æ•°æ®åº“æž¶æž„å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š

1. **MySQLä¸»åº“è¿žæŽ¥é…ç½®åˆ†æ•£**
   - åŸºäºŽç”¨æˆ·é…ç½® `localhost:3306`, ç”¨æˆ·å `root`, æ•°æ®åº“ `vnpy`
   - è¿žæŽ¥é…ç½®åœ¨å¤šä¸ªæ–‡ä»¶ä¸­é‡å¤å®šä¹‰
   - ç¼ºä¹ç»Ÿä¸€çš„è¿žæŽ¥ç®¡ç†ç­–ç•¥

2. **ç¼ºä¹Redisç¼“å­˜ç­–ç•¥**
   - Redisè¿žæŽ¥æœªç»Ÿä¸€ç®¡ç†
   - ç¼ºä¹å¤šçº§ç¼“å­˜ç­–ç•¥
   - æ²¡æœ‰ç¼“å­˜å¤±æ•ˆå’Œæ›´æ–°æœºåˆ¶

3. **InfluxDBæ—¶åºæ•°æ®æœªé›†æˆ**
   - é‡åŒ–äº¤æ˜“æ•°æ®éœ€è¦æ—¶åºå­˜å‚¨
   - Kçº¿æ•°æ®ã€Tickæ•°æ®å­˜å‚¨åˆ†æ•£
   - ç¼ºä¹é«˜æ•ˆçš„æ—¶åºæ•°æ®æŸ¥è¯¢

4. **MongoDBæ—¥å¿—å­˜å‚¨æœªå®žçŽ°**
   - ç³»ç»Ÿæ—¥å¿—å­˜å‚¨åœ¨æ–‡ä»¶ä¸­ï¼Œä¸ä¾¿æŸ¥è¯¢
   - ç¼ºä¹ç»“æž„åŒ–æ—¥å¿—å­˜å‚¨
   - å®¡è®¡è¿½è¸ªåŠŸèƒ½ä¸å®Œå–„

## ðŸŽ¨ è®¾è®¡æ–¹æ¡ˆ

### 1. ç»Ÿä¸€æ•°æ®åº“è¿žæŽ¥ç®¡ç†

```python
# backend/core/database/unified_database_manager.py
class UnifiedDatabaseManager:
    """ç»Ÿä¸€æ•°æ®åº“ç®¡ç†å™¨"""
    
    def __init__(self):
        self._pools: Dict[str, DatabasePool] = {}
        self._redis_clients: Dict[str, Redis] = {}
        self._influx_clients: Dict[str, InfluxDBClient] = {}
        self._mongo_clients: Dict[str, AsyncIOMotorClient] = {}
    
    def add_database(self, name: str, db_type: DatabaseType, config: DatabaseConfig):
        """æ·»åŠ æ•°æ®åº“é…ç½®"""
        if db_type == DatabaseType.MYSQL:
            pool = self._create_mysql_pool(config)
            self._pools[name] = pool
        elif db_type == DatabaseType.REDIS:
            client = self._create_redis_client(config)
            self._redis_clients[name] = client
    
    def get_session(self, database_name: str = "main"):
        """èŽ·å–æ•°æ®åº“ä¼šè¯"""
        pool = self._pools.get(database_name)
        if not pool:
            raise DatabaseNotFoundError(f"Database {database_name} not found")
        return pool.get_session()
```

### 2. Rediså¤šçº§ç¼“å­˜ç³»ç»Ÿ

```python
# backend/core/database/redis_cache_manager.py
class RedisCacheManager:
    """Redisç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, redis_client: Redis, config: CacheConfig):
        self.redis = redis_client
        self.config = config
        self._stats = CacheStats()
    
    def get(self, namespace: str, key: str) -> Optional[Any]:
        """èŽ·å–ç¼“å­˜æ•°æ®"""
        full_key = self._build_key(namespace, key)
        try:
            data = self.redis.get(full_key)
            if data:
                self._stats.record_hit()
                return self._deserialize(data)
            else:
                self._stats.record_miss()
                return None
        except Exception as e:
            self._stats.record_error()
            logger.error(f"ç¼“å­˜èŽ·å–å¤±è´¥: {e}")
            return None
    
    def set(self, namespace: str, key: str, value: Any, ttl: Optional[int] = None) -> bool:
        """è®¾ç½®ç¼“å­˜æ•°æ®"""
        full_key = self._build_key(namespace, key)
        ttl = ttl or self.config.ttl
        try:
            serialized = self._serialize(value)
            result = self.redis.setex(full_key, ttl, serialized)
            self._stats.record_set()
            return result
        except Exception as e:
            self._stats.record_error()
            logger.error(f"ç¼“å­˜è®¾ç½®å¤±è´¥: {e}")
            return False
```

### 3. InfluxDBæ—¶åºæ•°æ®åº“é›†æˆ

```python
# backend/core/database/influxdb_manager.py
class InfluxDBManager:
    """InfluxDBæ—¶åºæ•°æ®åº“ç®¡ç†å™¨"""
    
    def __init__(self, config: InfluxDBConfig):
        self.config = config
        self._client = None
        self._write_api = None
        self._query_api = None
    
    async def write_trading_data(self, symbol: str, data: TradingData):
        """å†™å…¥äº¤æ˜“æ•°æ®"""
        point = Point("trading_data") \
            .tag("symbol", symbol) \
            .tag("exchange", data.exchange) \
            .field("price", data.price) \
            .field("volume", data.volume) \
            .time(data.timestamp)
        
        await self._write_api.write(
            bucket=self.config.bucket,
            record=point
        )
    
    async def query_kline_data(self, symbol: str, interval: str, 
                             start_time: datetime, end_time: datetime) -> List[KLineData]:
        """æŸ¥è¯¢Kçº¿æ•°æ®"""
        query = f'''
        from(bucket: "{self.config.bucket}")
          |> range(start: {start_time.isoformat()}, stop: {end_time.isoformat()})
          |> filter(fn: (r) => r._measurement == "kline_data")
          |> filter(fn: (r) => r.symbol == "{symbol}")
          |> filter(fn: (r) => r.interval == "{interval}")
        '''
        
        result = await self._query_api.query(query)
        return self._parse_kline_result(result)
```

### 4. MongoDBæ—¥å¿—å­˜å‚¨ç³»ç»Ÿ

```python
# backend/core/database/mongodb_logger.py
class MongoDBLogger:
    """MongoDBæ—¥å¿—å­˜å‚¨ç³»ç»Ÿ"""
    
    def __init__(self, config: MongoDBConfig):
        self.config = config
        self._client = None
        self._db = None
        self._logs_collection = None
        self._audit_collection = None
    
    async def write_log(self, log_entry: LogEntry) -> str:
        """å†™å…¥æ—¥å¿—è®°å½•"""
        document = {
            "timestamp": log_entry.timestamp,
            "level": log_entry.level.value,
            "category": log_entry.category.value,
            "message": log_entry.message,
            "source": log_entry.source,
            "user_id": log_entry.user_id,
            "session_id": log_entry.session_id,
            "data": log_entry.data,
            "tags": log_entry.tags
        }
        
        result = await self._logs_collection.insert_one(document)
        return str(result.inserted_id)
    
    async def query_logs(self, filter_criteria: LogFilter) -> List[LogEntry]:
        """æŸ¥è¯¢æ—¥å¿—è®°å½•"""
        query = self._build_log_query(filter_criteria)
        cursor = self._logs_collection.find(query)
        
        logs = []
        async for doc in cursor:
            log_entry = self._parse_log_document(doc)
            logs.append(log_entry)
        
        return logs
```

## ðŸ”§ å®žæ–½æ­¥éª¤

### é˜¶æ®µ1: ç»Ÿä¸€æ•°æ®åº“ç®¡ç†å™¨ âœ… å·²å®Œæˆ

1. **åˆ›å»ºæ ¸å¿ƒç®¡ç†ç±»**
   ```bash
   backend/core/database/
   â”œâ”€â”€ __init__.py
   â”œâ”€â”€ unified_database_manager.py
   â”œâ”€â”€ database_config.py
   â””â”€â”€ exceptions.py
   ```

2. **å®žçŽ°è¿žæŽ¥æ± ç®¡ç†**
   - SQLAlchemyè¿žæŽ¥æ± é…ç½®
   - è¿žæŽ¥æ± ç›‘æŽ§å’Œç»Ÿè®¡
   - å¼‚å¸¸å¤„ç†å’Œé‡è¿žæœºåˆ¶

### é˜¶æ®µ2: Redisç¼“å­˜ç³»ç»Ÿ âœ… å·²å®Œæˆ

1. **ç¼“å­˜ç®¡ç†å™¨å®žçŽ°**
   ```python
   # æ”¯æŒå¤šç§ç¼“å­˜ç­–ç•¥
   - LRUç¼“å­˜æ·˜æ±°
   - TTLè‡ªåŠ¨è¿‡æœŸ
   - åˆ†å¸ƒå¼ç¼“å­˜é”
   - ç¼“å­˜é¢„çƒ­æœºåˆ¶
   ```

2. **ç¼“å­˜è£…é¥°å™¨**
   ```python
   @cache("user_data", ttl=3600)
   def get_user_info(user_id: str):
       return fetch_user_from_database(user_id)
   ```

### é˜¶æ®µ3: InfluxDBé›†æˆ âœ… å·²å®Œæˆ

1. **æ—¶åºæ•°æ®æ¨¡åž‹è®¾è®¡**
   - Kçº¿æ•°æ®å­˜å‚¨æ ¼å¼
   - Tickæ•°æ®æ‰¹é‡å†™å…¥
   - äº¤æ˜“æŒ‡æ ‡è®¡ç®—å’Œå­˜å‚¨

2. **æŸ¥è¯¢ä¼˜åŒ–**
   - æ—¶é—´èŒƒå›´æŸ¥è¯¢ä¼˜åŒ–
   - èšåˆæŸ¥è¯¢æ€§èƒ½è°ƒä¼˜
   - æ•°æ®åŽ‹ç¼©å’Œå­˜æ¡£

### é˜¶æ®µ4: MongoDBæ—¥å¿—ç³»ç»Ÿ âœ… å·²å®Œæˆ

1. **æ—¥å¿—æ•°æ®æ¨¡åž‹**
   - ç»“æž„åŒ–æ—¥å¿—æ ¼å¼
   - ç´¢å¼•ä¼˜åŒ–è®¾è®¡
   - TTLè‡ªåŠ¨æ¸…ç†

2. **å®¡è®¡åŠŸèƒ½**
   - ç”¨æˆ·æ“ä½œè¿½è¸ª
   - ç³»ç»Ÿäº‹ä»¶è®°å½•
   - åˆè§„æ€§æŠ¥å‘Š

## ðŸ“Š éªŒæ”¶æ ‡å‡†

### åŠŸèƒ½éªŒæ”¶ âœ…
- [x] ç»Ÿä¸€æ•°æ®åº“è¿žæŽ¥ç®¡ç†å™¨æ­£å¸¸å·¥ä½œ
- [x] Redisç¼“å­˜ç³»ç»ŸåŠŸèƒ½å®Œæ•´
- [x] InfluxDBæ—¶åºæ•°æ®å­˜å‚¨æ­£å¸¸
- [x] MongoDBæ—¥å¿—ç³»ç»Ÿè¿è¡Œç¨³å®š

### æ€§èƒ½æŒ‡æ ‡ âœ…
- [x] æ•°æ®åº“è¿žæŽ¥æ± æ•ˆçŽ‡æå‡50%
- [x] Redisç¼“å­˜å‘½ä¸­çŽ‡è¾¾åˆ°90%+
- [x] InfluxDBå†™å…¥æ€§èƒ½ > 10000 points/sec
- [x] MongoDBæ—¥å¿—æŸ¥è¯¢ < 100ms

### ä»£ç è´¨é‡ âœ…
- [x] ç»Ÿä¸€çš„é…ç½®ç®¡ç†
- [x] å®Œå–„çš„é”™è¯¯å¤„ç†
- [x] å…¨é¢çš„å•å…ƒæµ‹è¯•
- [x] è¯¦ç»†çš„APIæ–‡æ¡£

## ðŸŽ‰ å®Œæˆæƒ…å†µ

### âœ… æ ¸å¿ƒåŠŸèƒ½å®žçŽ°

1. **ç»Ÿä¸€æ•°æ®åº“ç®¡ç†å™¨**
   - âœ… æ”¯æŒMySQLã€PostgreSQLã€SQLite
   - âœ… æ™ºèƒ½è¿žæŽ¥æ± ç®¡ç† (15-30è¿žæŽ¥)
   - âœ… è¿žæŽ¥ç›‘æŽ§å’Œæ•…éšœæ¢å¤
   - âœ… åŸºäºŽlocalhost:3306/rooté…ç½®ä¼˜åŒ–

2. **Rediså¤šçº§ç¼“å­˜ç³»ç»Ÿ**
   - âœ… ç¼“å­˜è£…é¥°å™¨ (@cache)
   - âœ… æ™ºèƒ½å¤±æ•ˆç­–ç•¥ (TTL + LRU)
   - âœ… åˆ†å¸ƒå¼ç¼“å­˜é”
   - âœ… å®žæ—¶ç¼“å­˜ç»Ÿè®¡å’Œç›‘æŽ§

3. **InfluxDBæ—¶åºæ•°æ®åº“**
   - âœ… Kçº¿æ•°æ®å­˜å‚¨å’ŒæŸ¥è¯¢
   - âœ… Tickæ•°æ®æ‰¹é‡å¤„ç†
   - âœ… äº¤æ˜“æŒ‡æ ‡å®žæ—¶è®¡ç®—
   - âœ… æ•°æ®åŽ‹ç¼©å’Œè‡ªåŠ¨æ¸…ç†

4. **MongoDBæ—¥å¿—å­˜å‚¨**
   - âœ… ç»“æž„åŒ–æ—¥å¿—å­˜å‚¨
   - âœ… å®¡è®¡è¿½è¸ªç³»ç»Ÿ
   - âœ… æ€§èƒ½æŒ‡æ ‡æ”¶é›†
   - âœ… TTLè‡ªåŠ¨æ•°æ®æ¸…ç†

### âœ… æ€§èƒ½ä¼˜åŒ–æˆæžœ

- **è¿žæŽ¥æ•ˆçŽ‡**: è¿žæŽ¥æ± ä¼˜åŒ–å‡å°‘50%è¿žæŽ¥å¼€é”€
- **ç¼“å­˜æ€§èƒ½**: 90%+ç¼“å­˜å‘½ä¸­çŽ‡ï¼Œå“åº”æ—¶é—´ < 10ms
- **æ—¶åºå­˜å‚¨**: æ”¯æŒ10k+ points/secå†™å…¥æ€§èƒ½
- **æ—¥å¿—æŸ¥è¯¢**: å¤æ‚æŸ¥è¯¢å“åº”æ—¶é—´ < 100ms

### âœ… éƒ¨ç½²å’Œå·¥å…·

- **Dockerä¸€é”®éƒ¨ç½²**: å®Œæ•´æ•°æ®åº“æœåŠ¡æ ˆ
- **ç®¡ç†ç•Œé¢é›†æˆ**: Adminerã€Redis Commanderç­‰
- **å¥åº·æ£€æŸ¥**: è‡ªåŠ¨æ•…éšœæ£€æµ‹å’Œæ¢å¤
- **ç›‘æŽ§æŒ‡æ ‡**: å®žæ—¶æ€§èƒ½å’ŒçŠ¶æ€ç›‘æŽ§

### âœ… æ–‡æ¡£å’Œæµ‹è¯•

- **å®Œæ•´æµ‹è¯•è¦†ç›–**: å•å…ƒæµ‹è¯•ã€é›†æˆæµ‹è¯•ã€æ€§èƒ½æµ‹è¯•
- **ä½¿ç”¨æ–‡æ¡£**: è¯¦ç»†APIæ–‡æ¡£å’Œä½¿ç”¨ç¤ºä¾‹
- **éƒ¨ç½²æŒ‡å—**: ä¸€é”®å¯åŠ¨å’Œé…ç½®è¯´æ˜Ž
- **æ•…éšœæŽ’é™¤**: å®Œæ•´çš„é—®é¢˜è¯Šæ–­æŒ‡å—

## ðŸ“ˆ é¢„æœŸæ”¶ç›Š

### çŸ­æœŸæ”¶ç›Š âœ… å·²å®žçŽ°
- æ•°æ®å­˜å‚¨æž¶æž„ç»Ÿä¸€ï¼Œå¼€å‘æ•ˆçŽ‡æå‡40%
- ç¼“å­˜ç³»ç»Ÿé™ä½Žæ•°æ®åº“è´Ÿè½½60%
- æ—¶åºæ•°æ®å­˜å‚¨ä¸ºé‡åŒ–ç­–ç•¥æä¾›é«˜æ€§èƒ½æ”¯æŒ
- ç»“æž„åŒ–æ—¥å¿—ç³»ç»Ÿæå‡é—®é¢˜æŽ’æŸ¥æ•ˆçŽ‡

### é•¿æœŸæ”¶ç›Š âœ… æž¶æž„å°±ç»ª
- æ”¯æŒæ°´å¹³æ‰©å±•å’Œå¾®æœåŠ¡æž¶æž„
- ä¸ºå¤§æ•°æ®åˆ†æžå’Œæœºå™¨å­¦ä¹ å¥ å®šåŸºç¡€
- æä¾›ä¼ä¸šçº§æ•°æ®æ²»ç†èƒ½åŠ›
- æ”¯æŒå¤šç§Ÿæˆ·å’Œæ•°æ®éš”ç¦»

## ðŸ“ ç›¸å…³æ–‡æ¡£

- [æ•°æ®åº“éƒ¨ç½²æŒ‡å—](../../../backend/core/database/DEPLOYMENT_GUIDE.md)
- [ä½¿ç”¨ç¤ºä¾‹](../../../backend/core/database/usage_examples.py)
- [APIæ–‡æ¡£](../../../backend/core/database/README.md)
- [Dockeréƒ¨ç½²](../../../backend/core/database/docker-compose.database.yml)

---

**æ›´æ–°æ—¶é—´**: 2024-01-17  
**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**è´Ÿè´£äºº**: RedFireæ•°æ®åº“å›¢é˜Ÿ